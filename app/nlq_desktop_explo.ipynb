{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'uploads/NSF_Chem_2013.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e370de8d192a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mf_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'hist_{}.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_num\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mHeader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mnumber_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHeader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'uploads/NSF_Chem_2013.csv'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import textmining\n",
    "import lda\n",
    "import textmining\n",
    "import nltk.corpus\n",
    "import os\n",
    "\n",
    "\n",
    "#a = 'uploads/NSF_Bio_2015.csv'\n",
    "#a = 'uploads/NSF_plasma.csv'\n",
    "#a = 'uploads/NSF_Phy_2013.csv'\n",
    "#a = 'uploads/NSF_Chem_2013.csv'\n",
    "\n",
    "a = 'uploads/NSF_Chem_2013.csv'\n",
    "\n",
    "prev_num = 0\n",
    "for f in os.listdir('static'):\n",
    "\tif f[0:4] == 'hist':\n",
    "\t\tnum = int(f.split('_')[-1].split('.')[0])\n",
    "\t\tif num > prev_num:\n",
    "\t\t\tprev_num = num\n",
    "f_name = 'hist_{}.png'.format(prev_num+1)\n",
    "\n",
    "with open(a) as f:\n",
    "\tHeader = f.next().split(',')\n",
    "number_name = Header[0]\n",
    "text_name = Header[1][:-2]\n",
    "\n",
    "#Read the input file\n",
    "input_file = csv.DictReader(open(a))\n",
    "\n",
    "text = []\n",
    "number = []\n",
    "\n",
    "for row in input_file:\n",
    "    number.append(row[number_name])\n",
    "    text.append(row[text_name])\n",
    "\n",
    "d = len(text)\n",
    "n_topics = 30\n",
    "\n",
    "text_stop = []\n",
    "stop = set(stopwords.words('english'))\n",
    "stop |= {'new', 'made', 'use'}\n",
    "\n",
    "for i in range(len(text)):\n",
    "    sentence = text[i].lower()\n",
    "    A = [i for i in sentence.replace('<br/>',' ').split() if i not in stop]\n",
    "    A = [i[:-1] for i in A  if i[-1] == 's']\n",
    "    text_stop.append(' '.join(A))\n",
    "\n",
    "tdm = textmining.TermDocumentMatrix()\n",
    "\n",
    "for i in range(d):\n",
    "    tdm.add_doc(text_stop[i])\n",
    "\n",
    "# # create a temp variable with doc-term info\n",
    "temp = list(tdm.rows(cutoff=1))\n",
    "\n",
    "# get the vocab from first row\n",
    "vocab = tuple(temp[0])\n",
    "\n",
    "# # get document-term matrix from remaining rows\n",
    "X = np.array(temp[1:])\n",
    "\n",
    "\n",
    "#tdm.write_csv('matrix.csv', cutoff=1)\n",
    "topics = []\n",
    "\n",
    "model = lda.LDA(n_topics, n_iter=500, random_state=1)\n",
    "model.fit(X)  # model.fit_transform(X) is also available\n",
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "n_top_words = 8\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    topics.append('Topic {}: {}'.format(i+1, ' '.join(topic_words)))\n",
    "    print('Topic {}: {}'.format(i+1, ' '.join(topic_words)))\n",
    "\n",
    "# get results\n",
    "topic_word = model.topic_word_ \n",
    "doc_topic = model.doc_topic_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('static/topic_table', 'w') as f:\n",
    "    # create header\n",
    "    #header = 'document'\n",
    "    #for k in range(n_topics):\n",
    "    #   header += ', pr_topic_{}'.format(k)\n",
    "    #f.write(header + '\\n')\n",
    "\n",
    "    # write one row for each document\n",
    "    # col 1 : document number\n",
    "    # cols 2 -- : topic probabilities\n",
    "    for k in range(d):\n",
    "        # format probabilities into string\n",
    "        str_probs = ','.join(['{:.5e}'.format(pr) for pr in doc_topic[k,:]])\n",
    "        # write line to file\n",
    "        #f.write('{}, {}\\n'.format(k, str_probs))\n",
    "        f.write('{}\\n'.format(str_probs))\n",
    "\n",
    "\t\t\n",
    "dat = np.genfromtxt ('static/topic_table', delimiter=\",\")\n",
    "\n",
    "M = []\n",
    "for i in range(len(number)):\n",
    "\t\tM.append(dat[i,:]*float(number[i]))\n",
    "\n",
    "M = sum(M)\n",
    "Total = sum(M)\n",
    "\n",
    "x=np.arange(1, n_topics+1, 1)\n",
    "y=M\n",
    "\n",
    "ax = sns.barplot(x, y, color='Blue')\n",
    "ax.set(xlabel='Topics', ylabel=number_name)\n",
    "ax.set_title('Total: {} {}'.format(int(Total), number_name))\n",
    "num = 1\n",
    "sns.plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in range(d):\n",
    "    str_probs = [pr for pr in doc_topic[k,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0012987 ,  0.07922078,  0.0012987 ,  0.01428571,  0.0012987 ,\n",
       "        0.01428571,  0.0012987 ,  0.0012987 ,  0.0012987 ,  0.0012987 ,\n",
       "        0.11818182,  0.0012987 ,  0.04025974,  0.0012987 ,  0.0012987 ,\n",
       "        0.01428571,  0.04025974,  0.0012987 ,  0.01428571,  0.18311688,\n",
       "        0.0012987 ,  0.0012987 ,  0.0012987 ,  0.01428571,  0.0012987 ,\n",
       "        0.42987013,  0.0012987 ,  0.0012987 ,  0.0012987 ,  0.01428571])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_file = csv.DictReader(open('uploads/NSF_bio_2015.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_file = pd.read_csv(open('uploads/NSF_bio_2015.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5365"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
