{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import textmining\n",
    "import lda\n",
    "import textmining\n",
    "import nltk.corpus\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"NSF_test.csv\") as f:\n",
    "    Header = f.next().split(',')\n",
    "number_name = Header[0]\n",
    "text_name = Header[1][:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_file = csv.DictReader(open(\"NSF_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = []\n",
    "number = []\n",
    "for row in input_file:\n",
    "    number.append(row[number_name])\n",
    "    text.append(row[text_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_stop = []\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "text_stop = []\n",
    "stop = set(stopwords.words('english'))\n",
    "stop |= {'br', 'research', 'new', 'made', 'use'}\n",
    "\n",
    "for i in range(len(text)):\n",
    "    sentence = text[i].lower()\n",
    "    A = [i for i in sentence.replace('<br/>',' ').split() if i not in stop]\n",
    "    A = [i[:-1] for i in A  if i[-1] == 's']\n",
    "    #A = [wordnet.lemmatize(word) for word in sentence]\n",
    "    text_stop.append(' '.join(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inne',\n",
       " 'dougla',\n",
       " 'solti',\n",
       " 'solti',\n",
       " 'flavor',\n",
       " 'member',\n",
       " 'by-product',\n",
       " 'flavor',\n",
       " 'tea',\n",
       " 'compound',\n",
       " 'support',\n",
       " 'compound',\n",
       " 'studie',\n",
       " 'pathway',\n",
       " 'compound',\n",
       " 'factor',\n",
       " 'dataset',\n",
       " 'acros',\n",
       " 'processe',\n",
       " 'require',\n",
       " 'expert',\n",
       " 'genetic',\n",
       " 'student',\n",
       " 'frontier',\n",
       " 'genomic',\n",
       " 'link',\n",
       " 'product',\n",
       " \"children'\",\n",
       " 'offer',\n",
       " 'display',\n",
       " 'tour',\n",
       " 'scientist',\n",
       " 'represent',\n",
       " 'angiosperm',\n",
       " 'subfamilie',\n",
       " 'difference',\n",
       " 'synthesi',\n",
       " 'iridoid',\n",
       " 'compound',\n",
       " 'flavor',\n",
       " 'integrate',\n",
       " 'dataset',\n",
       " 'pathway',\n",
       " 'transcriptome',\n",
       " 'metabolome',\n",
       " 'specie',\n",
       " 'specie',\n",
       " 'level',\n",
       " 'thu',\n",
       " 'resource',\n",
       " 'gene',\n",
       " 'event',\n",
       " 'mechanism',\n",
       " 'hypothese',\n",
       " 'gene',\n",
       " 'resource',\n",
       " 'sequence']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "snowball = SnowballStemmer('english')\n",
    "wordnet = WordNetLemmatizer()\n",
    "\n",
    "docs = text_stop[0].split()\n",
    "\n",
    "docs_porter = [porter.stem(word) for word in docs]\n",
    "               \n",
    "docs_snowball = [snowball.stem(word) for word in docs]\n",
    "\n",
    "docs_wordnet = [wordnet.lemmatize(word) for word in docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['infectiou',\n",
       " 'dendrobatidi',\n",
       " 'spread',\n",
       " 'salamander',\n",
       " '(genu',\n",
       " 'show',\n",
       " 'population',\n",
       " 'investigator',\n",
       " 'hypothesi',\n",
       " 'increase',\n",
       " 'level',\n",
       " 'researcher',\n",
       " 'hypothesi',\n",
       " 'historie',\n",
       " 'los',\n",
       " \"population'\",\n",
       " 'infectiou',\n",
       " 'implication',\n",
       " 'insight',\n",
       " 'undergraduate',\n",
       " 'minoritie',\n",
       " 'group',\n",
       " 'student',\n",
       " 'tool',\n",
       " 'skill',\n",
       " 'challenge',\n",
       " 'student',\n",
       " 'receive',\n",
       " 'querie',\n",
       " 'finding',\n",
       " 'publication',\n",
       " 'presentation',\n",
       " 'pi']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = len(text)\n",
    "n_topics = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: studie tool activitie processe mutation technique protein residue\n",
      "Topic 2: population specie investigator gene factor insight difference individual\n",
      "Topic 3: specie gene trait proces rate studie teacher organism\n",
      "Topic 4: student gene mechanism activitie opportunitie variou group represent\n",
      "Topic 5: student provide science project technique program event participant\n",
      "Topic 6: tool goal impact resource analyse les require change\n",
      "Topic 7: undergraduate effect student region heterosi fitnes combination mutation\n",
      "Topic 8: microbe pattern communitie acros dynamic mean prediction goal\n",
      "Topic 9: protein studie group proces channel question major use\n",
      "Topic 10: method physic interaction biophysic system processe model propertie\n",
      "Topic 11: mechanism genetic insect thu seed function strategie sequence\n",
      "Topic 12: specie researcher scientist tree addres numerou forest u\n",
      "Topic 13: relationship animal group use stream lake rate source\n",
      "Topic 14: cell student molecule processe analysi propertie pathway proces\n",
      "Topic 15: population experiment module genome disease contribute cause teacher\n",
      "Topic 16: plant pathway arabidopsi stres tool level technologie cell\n",
      "Topic 17: hypothesi difference approache form type genomic pi acros\n",
      "Topic 18: factor biosynthesi studie opportunitie synthesi product feature abilitie\n",
      "Topic 19: protein student structure motion measurement principle result ion\n",
      "Topic 20: method interaction pathogen biologist host student investigator insect\n",
      "Topic 21: model result effect aim material ecosystem principle outcome\n",
      "Topic 22: interaction impact area benefit previou provide result bee\n",
      "Topic 23: dynamic student experiment interaction structure include serie association\n",
      "Topic 24: response asses cue workshop structure embryo method signal\n",
      "Topic 25: student change researcher teacher focu material photosynthesi proces\n",
      "Topic 26: mechanism result student component plant opportunitie role play\n",
      "Topic 27: organism mechanism acros basi compound behavior u aim\n",
      "Topic 28: effort result technique function change challenge level focu\n",
      "Topic 29: enzyme student course undergraduate chemical reaction aspect acid\n",
      "Topic 30: system scientist approache studie concept network measurement activitie\n"
     ]
    }
   ],
   "source": [
    "\tfor i in range(len(text)):\n",
    "\t    sentence = text[i].lower()\n",
    "\t    A = [i for i in sentence.split() if i not in stop]\n",
    "\t    text_stop.append(' '.join(A))\n",
    "\n",
    "\ttdm = textmining.TermDocumentMatrix()\n",
    "\n",
    "\tfor i in range(d):\n",
    "\t    tdm.add_doc(text_stop[i])\n",
    "\n",
    "\t# # create a temp variable with doc-term info\n",
    "\ttemp = list(tdm.rows(cutoff=1))\n",
    "\n",
    "\t# get the vocab from first row\n",
    "\tvocab = tuple(temp[0])\n",
    "\n",
    "\t# # get document-term matrix from remaining rows\n",
    "\tX = np.array(temp[1:])\n",
    "\n",
    "\n",
    "\t#tdm.write_csv('matrix.csv', cutoff=1)\n",
    "\n",
    "\tTopics = []\n",
    "\n",
    "\tmodel = lda.LDA(n_topics, n_iter=100, random_state=1)\n",
    "\tmodel.fit(X)  # model.fit_transform(X) is also available\n",
    "\ttopic_word = model.topic_word_  # model.components_ also works\n",
    "\tn_top_words = 8\n",
    "\tfor i, topic_dist in enumerate(topic_word):\n",
    "\t    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "\t    Topics.append('Topic {}: {}'.format(i+1, ' '.join(topic_words)))\n",
    "\t    print('Topic {}: {}'.format(i+1, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\ttopic_word = model.topic_word_ \n",
    "\tdoc_topic = model.doc_topic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\twith open('topic_table.csv', 'w') as f:\n",
    "\t    # create header\n",
    "\t    #header = 'document'\n",
    "\t    #for k in range(n_topics):\n",
    "\t    #   header += ', pr_topic_{}'.format(k)\n",
    "\t    #f.write(header + '\\n')\n",
    "\n",
    "\t    # write one row for each document\n",
    "\t    # col 1 : document number\n",
    "\t    # cols 2 -- : topic probabilities\n",
    "\t    for k in range(d):\n",
    "\t        # format probabilities into string\n",
    "\t        str_probs = ','.join(['{:.5e}'.format(pr) for pr in doc_topic[k,:]])\n",
    "\t        # write line to file\n",
    "\t        #f.write('{}, {}\\n'.format(k, str_probs))\n",
    "\t        f.write('{}\\n'.format(str_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\tdat = np.genfromtxt ('topic_table.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = []\n",
    "for i in range(len(number)):\n",
    "    M.append(dat[i,:]*int(number[i]))\n",
    "M = sum(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7183232.2122107 ,  7155194.8301095 ,  9588536.30739408,\n",
       "        8384503.53635426,  8471701.63185506,  6806928.63669264,\n",
       "        5409524.25259089,  5752135.85771036,  6628760.92671108,\n",
       "        9744640.60595699,  7086477.39102612,  8697243.58989591,\n",
       "        4168758.19068995,  9717119.32882624,  4635155.19235699,\n",
       "        7764629.07932004,  6783969.41648073,  4664172.93170616,\n",
       "        8756461.12449673,  6724847.10156213,  5598046.81024881,\n",
       "        5741881.94771134,  6201336.6472921 ,  6337254.42520244,\n",
       "        7939606.50318772,  7401858.76042558,  6645849.47407917,\n",
       "        6475091.86599542,  7554559.22088301,  8171682.34982267])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.arange(1, n_topics+1, 1)\n",
    "y=M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7b9d1449f717>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Topics'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "\tax = sns.barplot(x, y, color='Blue')\n",
    "\tax.set(xlabel='Topics', ylabel=number_name)\n",
    "\tax.set_title('Total')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
